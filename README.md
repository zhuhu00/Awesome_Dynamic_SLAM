# Awesome_Dynamic_SLAM [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

The following paper are the papers that focuses on the **SLAM in dynamic Environments** and **Life-long SLAM**. In the dynamic environment, there are two kinds of robust SLAM: First is **detection & removal**. Another is **detection & tracking**. Although the mapping part in dynamic environment is not my focus, but I will also put some articles yet also very interesting.

> **Vision** means that the pipeline is built with camera. Others are the same, such as **lidar**, **radar**, **sensor fusion**.

------

# Related survey papers:

- [**A survey: which features are required for dynamic visual simultaneous localization and mapping?**](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8285453/pdf/42492_2021_Article_86.pdf). Zewen Xu,CAS. 2021

- [**State of the Art in Real-time Registration of RGB-D Images**](https://cg.cs.uni-bonn.de/aigaion2root/attachments/StateoftheArtinReal-timeRegistrationofRGB-DImages.pdf). Stotko, Patrick. University of Bonn. 2016
- [**Visual SLAM and Structure from Motion in Dynamic Environments: A Survey**](https://dl.acm.org/doi/pdf/10.1145/3177853).  University of Oxford. 2018
- [**State of the Art on 3D Reconstruction with RGB-D Cameras**](https://www.cg.informatik.uni-siegen.de/data/Publications/2018/star1009-main.pdf). Michael ZollhÃ¶fer. Stanford University. 2018

# Dynamic Object Detection and *Removal*

- [DeFlowSLAM: Self-Supervised Scene Motion Decomposition for Dynamic Dense  SLAM](https://arxiv.org/pdf/2207.08794v1)
  
  - æµ™æ±Ÿå¤§å­¦ï¼Œè²Œä¼¼æ˜¯DROID-SLAMå¾—éƒ¨åˆ†ï¼Œå°†å…‰æµåˆ†æˆäº†åŠ¨æ€ç‰©ä½“å’Œé™æ€ï¼Œåˆ†åˆ«è¿›è¡ŒåŽç»­çš„æ“ä½œã€‚æ•ˆæžœçœ‹èµ·æ¥ä¹Ÿå¾ˆä¸é”™ã€‚[page](https://zju3dv.github.io/deflowslam/)ï¼Œ[code](https://github.com/zju3dv/DeFlowSLAM)
  
- [Efficient Spatial-Temporal Information Fusion for LiDAR-Based 3D Moving  Object Segmentation](https://arxiv.org/pdf/2207.02201)

  - æ¯«æœ«æ™ºè¡Œï¼Œ**[code](https://github.com/haomo-ai/MotionSeg3D)**ï¼ŒåŠ¨æ€æ£€æµ‹

- [[2203.03923] ROLL: Long-Term Robust LiDAR-based Localization With Temporary Mapping in Changing Environments](https://arxiv.org/pdf/2203.03923) IROS 2022

  - codeï¼šhttps://github.com/HaisenbergPeng/ROLL

- [POCD: Probabilistic Object-Level Change Detection and Volumetric Mapping  in Semi-Static Scenes](https://arxiv.org/pdf/2205.01202v1)

  - RSS 2022ï¼ŒåŠé™æ€åœºæ™¯ä¸­çš„åœ°å›¾æ›´æ–°

- J. Schauer and A. Nuchter, â€œ**The Peopleremoverâ€”Removing Dynamic Objects From 3-D Point Cloud Data by Traversing a Voxel Occupancy Grid**,â€ *IEEE Robot. Autom. Lett.*, vol. 3, no. 3, pp. 1679â€“1686, Jul. 2018, doi: [10.1109/LRA.2018.2801797](https://doi.org/10.1109/LRA.2018.2801797).

  - åŸºäºŽä½“ç´ éåŽ†çš„æ–¹æ³•çš„è¿åŠ¨å¯¹è±¡åŽ»é™¤ï¼Œè™½ç„¶è¿™ç§æ–¹æ³•æœ‰å¾ˆå¤šçš„ç¼ºç‚¹ï¼Œä½†æ˜¯è®ºæ–‡æå‡ºäº†å¾ˆå¤šçš„trickï¼Œæ¥è§£å†³è¿™äº›é—®é¢˜ï¼Œçœ‹èµ·æ¥æ•ˆæžœè¿˜æ˜¯ä¸é”™çš„ã€‚
  - codeï¼Œvideo

- N. Rufus, U. K. R. Nair, A. V. S. S. B. Kumar, V. Madiraju, and K. M. Krishna, â€œ[**SROM: Simple Real-time Odometry and Mapping using LiDAR data for Autonomous Vehicles**.](http://arxiv.org/abs/2005.02042)â€ IV 2020
  - è¾ƒä¸ºç²—æš´çš„åŽ»é™¤å¯èƒ½çš„è¿åŠ¨å¯¹è±¡ï¼ŒåŽ»é™¤åœ°é¢åŽå†å–å‡º

- M. Schorghuber, D. Steininger, Y. Cabon, M. Humenberger, and M. Gelautz, â€œ**[SLAMANTIC - Leveraging Semantics to Improve VSLAM in Dynamic Environments,](https://openaccess.thecvf.com/content_ICCVW_2019/papers/DL4VSLAM/Schorghuber_SLAMANTIC_-_Leveraging_Semantics_to_Improve_VSLAM_in_Dynamic_Environments_ICCVW_2019_paper.pdf)**â€ ICCV 2019 workshop
  - è§†è§‰SLAMï¼ŒåŠ¨æ€çŽ¯å¢ƒã€‚é€šè¿‡è¯­ä¹‰å¯¹ç‚¹çš„ç½®ä¿¡åº¦è¿›è¡Œè®¡ç®—ï¼Œé«˜ç½®ä¿¡åº¦çš„ç‚¹æ¥è¾…åŠ©ä½Žç½®ä¿¡åº¦çš„ç‚¹ï¼Œæœ€ç»ˆç¡®å®šç”¨äºŽå®šä½å’Œå»ºå›¾çš„éƒ¨åˆ†ã€‚

- S. Gu, S. Yao, J. Yang, and H. Kong, â€œ**[Semantics-Guided Moving Object Segmentation with 3D LiDAR]( http://arxiv.org/abs/2205.03186)**,â€  arxiv 2022.05
  - åŠ¨æ€ç‰©ä½“çš„åˆ†å‰²ç½‘ç»œï¼Œä¹Ÿæ˜¯rangenetçš„æ€æƒ³é‚£å¥—ã€‚

- Y. Pan, B. Gao, J. Mei, S. Geng, C. Li, and H. Zhao, â€œ**[SemanticPOSS: A Point Cloud Dataset with Large Quantity of Dynamic Instances](https://arxiv.org/pdf/2002.09147v1.pdf)**,â€ IV 2020
  - åŠ¨æ€ç‰©ä½“å®¤å¤–æ•°æ®é›†ï¼ŒåŒ—å¤§ï¼Œ[ç½‘ç«™](http://www.poss.pku.edu.cn/semanticposs.html)

- S. Pagad, D. Agarwal, S. Narayanan, K. Rangan, H. Kim, and G. Yalla, â€œ**[Robust Method for Removing Dynamic Objects from Point Clouds](https://drive.google.com/file/d/1o73aG85OpuDmAUsjkgKaVwrG6d48aOin/view)**,â€ ICRA 2020
  - [video](https://www.youtube.com/watch?v=d2rbSP9IkkY)ï¼ŒåŠ¨æ€åŽ»é™¤

- L. Sun, Z. Yan, A. Zaganidis, C. Zhao, and T. Duckett, â€œ**Recurrent-OctoMap: Learning State-Based Map Refinement for Long-Term Semantic Mapping With 3-D-Lidar Data**,â€ RAL
  - life long slam 

- P. Egger, P. V. K. Borges, G. Catt, A. Pfrunder, R. Siegwart, and R. DubÃ©, â€œ**PoseMap: Lifelong, Multi-Environment 3D LiDAR Localization**,â€ IROS 2018
  - lifelong slamï¼ŒETH SALç»„

- DynamicFilter: **an Online Dynamic Objects Removal Framework for Highly Dynamic Environments**ï¼ŒICRA 2022
  - IJRRå¤§ä½¬ï¼Œå¯æƒœä¸å¼€æºã€‚ã€‚ï¼Œæ¸¯å¤§ï¼Œå—ç§‘å¤§

- X. Ma, Y. Wang, B. Zhang, H.-J. Ma, and C. Luo, â€œ**[DynPL-SVO: A New Method Using Point and Line Features for Stereo Visual Odometry in Dynamic Scenes](https://arxiv.org/abs/2205.08207v1)**.â€ arXiv, May 17, 2022
  - ä½¿ç”¨ç‚¹å’Œçº¿ç‰¹å¾çš„åŒç›®è§†è§‰é‡Œç¨‹è®¡ï¼ŒåŠ¨æ€åŽ»é™¤çš„è®ºæ–‡
  - ä¸œåŒ—å¤§å­¦ï¼Œä¹Ÿè¿˜æ²¡æœ‰å¼€æº

- M. T. LÃ¡zaro, R. Capobianco, and G. Grisetti, â€œ**[Efficient Long-term Mapping in Dynamic Environments](https://www.researchgate.net/profile/Maria-Lazaro-12/publication/330586668_Efficient_Long-term_Mapping_in_Dynamic_Environments/links/5f26efbe458515b729fe2f1b/Efficient-Long-term-Mapping-in-Dynamic-Environments.pdf)**,â€ IROS 2018
  - é«˜æ•ˆçš„ICPæ–¹æ¡ˆï¼Œå¹¶ä¸”å®žçŽ°äº†åœ°å›¾å®žä½“çš„åˆå¹¶ã€‚ç”±äºŽå¤„ç†çš„æ˜¯2Dåœ°å›¾ï¼Œå› æ­¤ä¹Ÿå°±æ²¡æœ‰é‚£ä¹ˆå¤šçš„éœ€è¦å¤„ç†çš„ä¸œè¥¿ã€‚å¯ä»¥ç›´æŽ¥ç”¨ç‚¹å¯è§†åŒ–æ¥åŽ»é™¤è¿åŠ¨çš„ç‚¹äº‘ã€‚
  - **[code](https://gitlab.com/srrg-software/srrg_mapper2d_ros)**ï¼Œ

- T. KrajnÃ­k, J. P. Fentanes, J. M. Santos, and T. Duckett, â€œ**[FreMEn: Frequency Map Enhancement for Long-Term Mobile Robot Autonomy in Changing Environments](http://strands.acin.tuwien.ac.at/publications/y4/krajnik_TRO.pdf)**,â€ TRO 2017

- G. Kurz, M. Holoch, and P. Biber, â€œ[**Geometry-based Graph Pruning for Lifelong SLAM**](http://arxiv.org/abs/2110.01286).â€ IROS 2021
  - æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•è€ƒè™‘äº†å‡ ä½•å‡†åˆ™æ¥é€‰æ‹©è¦å‰ªæžçš„é¡¶ç‚¹ã€‚è¿™æ˜¯æœ‰æ•ˆçš„ï¼Œæ˜“äºŽå®žçŽ°ï¼Œå¹¶å¯¼è‡´å…·æœ‰å‡åŒ€åˆ†å¸ƒçš„é¡¶ç‚¹çš„å›¾å½¢ï¼Œè¿™äº›é¡¶ç‚¹ä»ç„¶æ˜¯æœºå™¨äººè½¨è¿¹çš„ä¸€éƒ¨åˆ†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„è¾¹é™…åŒ–æ–¹æ³•ï¼Œä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•å¯¹é”™è¯¯çš„å¾ªçŽ¯é—­åŒ…å…·æœ‰æ›´å¼ºçš„é²æ£’æ€§ã€‚
    ä¸»è¦è®¾è®¡åˆ°SLAMåŽç«¯çš„ä¼˜åŒ–ï¼Œå½“åœ°å›¾æˆ–è€…æ˜¯å› å­å›¾æ›´æ–°æ—¶ï¼Œå¦‚ä½•å¯¹å› å­å›¾è¿›è¡Œå‰ªæžçš„é—®é¢˜ã€‚

- Quei-An Chen and Akihiro Tsukadaï¼Œâ€œ[**Flow Supervised Neural Radiance Fields for Static-Dynamic Decomposition**](https://drive.google.com/file/d/1kORAX0DOAs7m771EQ693aH7FeRwUqhCy/view)â€, ICRA 2022
  - AIè‘µï¼Œ[**code**](https://github.com/kwea123?tab=repositories)ï¼Œnerf+å…‰æµçš„åŠ¨æ€ç‰©ä½“ï¼ŒåŽ»é™¤å¹¶ä¿®å¤ï¼Œ[video](https://youtu.be/ixw9AkJpe30)ã€‚

- W. Ding, S. Hou, H. Gao, G. Wan, and S. Song, â€œ[**LiDAR Inertial Odometry Aided Robust LiDAR Localization System in Changing City Scenes**](https://songshiyu01.github.io/pdf/LIO_W.Ding_S.Song_ICRA2020.pdf),â€ ICRA 2020
  - ç™¾åº¦å‡ºå“çš„ä½¿ç”¨æ¿€å…‰å’ŒIMUï¼Œåœ¨è¿åŠ¨åœºæ™¯çš„å®šä½ï¼Œå¹¶ä¸”åœ¨ä¹‹å‰æž„å»ºçš„åœ°å›¾ä¸­ï¼Œé’ˆå¯¹åœºæ™¯æ–°å¢žåŠ çš„ä¸œè¥¿ï¼Œå°†ä¼šæ–°å»ºç›¸å…³çš„åœ°å›¾ã€‚
  - life-long SLAM

- G. D. Tipaldi, D. Meyer-Delius, and W. Burgard, â€œ**Lifelong localization in changing environments**,â€ IJRR 2013
  - life-longçš„å®šä½

- S. Zhu, X. Zhang, S. Guo, J. Li, and H. Liu, â€œ**Lifelong Localization in Semi-Dynamic Environment**,â€ ICRA 2021
  - æ¸…åŽï¼Œlife-longçš„å®šä½

- F. Pomerleau, P. KrÃ¼si, F. Colas, P. Furgale, and R. Siegwart, â€œ**Long-term 3D map maintenance in dynamic environments**,â€ ICRA 2014
  - åŠ¨æ€çŽ¯å¢ƒä¸­ï¼Œåœ°å›¾æ›´æ–°

- D. J. Yoon, T. Y. Tang, and T. D. Barfoot, â€œ[**Mapless Online Detection of Dynamic Objects in 3D Lidar**](http://arxiv.org/abs/1809.06972).â€ Conference on Computer and Robot Vision (CRV) 2019
  - ç‚¹äº‘åŠ¨æ€æ£€æµ‹

- M. Zhao *et al.*, â€œ[**A General Framework for Lifelong Localization and Mapping in Changing Environment**](http://arxiv.org/abs/2111.10946).â€  IROS 2021

  - é«˜ä»™æœºå™¨äººçš„**life-long** å®šä½çš„è®ºæ–‡
  - å¤šsessionçš„åœ°å›¾è¡¨ç¤ºå’Œä¸€ç§**é«˜æ•ˆçš„åœ¨çº¿åœ°å›¾æ›´æ–°ç­–ç•¥**ï¼Œå­ç³»ç»Ÿç»„æˆï¼šå±€éƒ¨æ¿€å…‰é›·è¾¾é‡Œç¨‹è®¡ï¼ˆLLOï¼‰ã€å…¨å±€æ¿€å…‰é›·è¾¾åŒ¹é…ï¼ˆGLMï¼‰å’Œä½å§¿å›¾ä¼˜åŒ–ï¼ˆPGRï¼‰ï¼ŒLLOçš„ä½œç”¨æ˜¯æž„å»ºä¸€ç³»åˆ—å±€éƒ¨ä¸€è‡´çš„å­åœ°å›¾ï¼ŒGLMå­ç³»ç»Ÿè´Ÿè´£è®¡ç®—ä¼ å…¥æ‰«æç‚¹äº‘å’Œå…¨å±€å­åœ°å›¾ä¹‹é—´çš„ç›¸å¯¹çº¦æŸï¼Œå¹¶å°†å­æ˜ åœ°å›¾å’Œçº¦æŸæ’å…¥PGRï¼ŒPGRæ˜¯ç³»ç»Ÿä¸­æœ€é‡è¦çš„éƒ¨åˆ†ï¼Œå®ƒä»ŽLLOå’ŒGLMæ”¶é›†å­åœ°å›¾å’Œçº¦æŸå…³ç³»ï¼Œä¿®å‰ªå¹¶ä¿å­˜åœ¨åŽ†å²åœ°å›¾ä¸­çš„æ—§çš„å­åœ°å›¾ï¼Œå¹¶æ‰§è¡Œå§¿åŠ¿å›¾ç¨€ç–åŒ–å’Œä¼˜åŒ–ã€‚

- D. Henning, T. Laidlow, and S. Leutenegger, â€œ[**BodySLAM: Joint Camera Localisation, Mapping, and Human Motion Tracking**](https://arxiv.org/pdf/2205.02301v1.pdf),â€ *arXiv:2205.02301

  - äººä½“æž„å»ºå’ŒSLAMç›¸ç»“åˆï¼Œä¸ŽAirDOSæœ‰ç‚¹ç±»ä¼¼

- Pfreundschuh, Patrick, et al. â€œ**[Dynamic Object Aware LiDAR SLAM Based on Automatic Generation of Training Data.](http://arxiv.org/abs/2104.03657)**â€ (*ICRA* *2021*)

  - **ETH ASL**,code, [video](https://youtu.be/LcDxd97r1Gc), [**dataset**](https://projects.asl.ethz.ch/datasets/doals), Lidar
  - ä½œè€…åŸºäºŽdeep-learningï¼ˆ3D-MiniNetç½‘ç»œï¼‰è¿›è¡Œå®žæ—¶3DåŠ¨æ€ç‰©ä½“æ£€æµ‹ï¼Œæ»¤é™¤åŠ¨æ€ç‰©ä½“åŽçš„ç‚¹äº‘è¢«å–‚ç»™LOAMï¼Œè¿›è¡Œå¸¸è§„çš„æ¿€å…‰SLAMã€‚æä¾›äº†å­¦ä¹ çš„æ–¹æ³•æ˜¯å±žäºŽæ— ç›‘ç£çš„æ–¹æ³•ã€‚

- Canovas Bruce, et al. â€œ[**Speed and Memory Efficient Dense RGB-D SLAM in Dynamic Scenes.**](https://doi.org/10.1109/IROS45743.2020.9341542)â€ (*IROS* 2020)
  - **GIPSA-lab**, [code](https://github.com/BruceCanovas/supersurfel_fusion), [video](https://youtu.be/hzzVVHUAO74)

- Yuan Xun and Chen Song. â€œ[**SaD-SLAM: A Visual SLAM Based on Semantic and Depth Information.**](http://ras.papercept.net/images/temp/IROS/files/0092.pdf)â€ *(IROS 2020)*
  - **USTC**, code, video

- Dong, Erqun, et al. â€œ[**Pair-Navi: Peer-to-Peer Indoor Navigation with Mobile Visual SLAM.**](https://cswu.me/papers/infocom19_pairnavi.pdf)â€ (ICCC 2019)
  - Tsinghua, [Code](https://github.com/Horacehxw/Dynamic_ORB_SLAM2), Video, [Slides](https://slidetodoc.com/pairnavi-peertopeer-indoor-navigation-with-mobile-visual-slam/).

- Ji Tete, et al. â€œ**[Towards Real-Time Semantic RGB-D SLAM in Dynamic Environments](https://arxiv.org/abs/2104.01316v1)**.â€ (ICRA 2021)

- Palazzolo Emanuele, et al. â€œ**[ReFusion: 3D Reconstruction in Dynamic Environments for RGB-D Cameras Exploiting Residuals.](https://arxiv.org/abs/1905.02082v3)**â€ (IROS 2019)
  - [code](https://github.com/PRBonn/refusion),[video](https://youtu.be/1P9ZfIS5-p4).University of Bonn.

- Arora Mehul, et al. ***[Mapping the Static Parts of Dynamic Scenes from 3D LiDAR Point Clouds Exploiting Ground Segmentation](https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/arora2021ecmr.pdf)***. p. 6.

- Chen Xieyuanli, et al. â€œ**[Moving Object Segmentation in 3D LiDAR Data: A Learning-Based Approach Exploiting Sequential Data](https://www.ipb.uni-bonn.de/pdfs/chen2021ral-iros.pdf)**.â€ *IEEE Robotics and Automation Letters*, 2021
  - [code](https://github.com/PRBonn/LiDAR-MOS). [video](https://www.youtube.com/watch?v=NHvsYhk4dhw). University of Bonn.

- Zhang Tianwei, et al. â€œ[**FlowFusion: Dynamic Dense RGB-D SLAM Based on Optical Flow.**](http://arxiv.org/abs/2003.05102.)â€(ICRA 2020)
  - code. [video](https://youtu.be/6yPGDdwKFLA).

- Zhang Tianwei, et al. â€œ**[AcousticFusion: Fusing Sound Source Localization to Visual SLAM in Dynamic Environments.](http://arxiv.org/abs/2108.01246)**â€,IROS 2021
  - [video](https://youtu.be/8eNikzp9LIQ). ç»“åˆå£°éŸ³ä¿¡å·

- 1. Liu Yubao and Miura Jun. â€œ[**RDS-SLAM: Real-Time Dynamic SLAM Using Semantic Segmentation Methods.**](https://doi.org/10.1109/ACCESS.2021.3050617)â€ *IEEE Access* 2021

  2. Liu Yubao and Miura Jun. â€œRDMO-SLAM: Real-Time Visual SLAM for Dynamic Environments Using Semantic Label Prediction With Optical Flow.â€ *IEEE Access*, vol. 9, 2021, pp. 106981â€“97. *IEEE Xplore*, https://doi.org/10.1109/ACCESS.2021.3100426.

  - [code](https://github.com/yubaoliu/RDS-SLAM.git
    ), video.

- Cheng Jiyu, et al. â€œ**Improving Visual Localization Accuracy in Dynamic Environments Based on Dynamic Region Removal.**â€ *IEEE Transactions on Automation Science and Engineering*, vol. 17, no. 3, July 2020, pp. 1585â€“96. *IEEE Xplore*, https://doi.org/10.1109/TASE.2020.2964938.

- Soares JoÃ£o Carlos Virgolino, et al. â€œ**[Crowd-SLAM: Visual SLAM Towards Crowded Environments Using Object Detection.](https://doi.org/10.1007/s10846-021-01414-1)**â€ *Journal of Intelligent & Robotic Systems* 2021

  - [code](https://github.com/virgolinosoares/Crowd-SLAM), video

- Kaveti Pushyami and Singh Hanumant. â€œ**[A Light Field Front-End for Robust SLAM in Dynamic Environments.](http://arxiv.org/abs/2012.10714)**â€.

- Kuen-Han Lin and Chieh-Chih Wang. â€œ**[Stereo-Based Simultaneous Localization, Mapping and Moving Object Tracking.](https://doi.org/10.1109/IROS.2010.5649653)**â€ IROS 2010

- Fu, H.; Xue, H.; Hu, X.; Liu, B. **[LiDAR Data Enrichment by Fusing Spatial and Temporal Adjacent Frames](https://doi.org/10.3390/rs13183640)**. *Remote Sens.* **2021**, *13*, 3640. 

- Qian, Chenglong, et al. ***RF-LIO: Removal-First Tightly-Coupled Lidar Inertial Odometry in High Dynamic Environments***. p. 8. IROS2021, **XJTU**

- K. Minoda, F. Schilling, V. WÃ¼est, D. Floreano, and T. Yairi, â€œ**[VIODE: A Simulated Dataset to Address the Challenges of Visual-Inertial Odometry in Dynamic Environments,](https://doi.org/10.1109/LRA.2021.3058073)**â€RAL 2021

  - åŠ¨æ€çŽ¯å¢ƒçš„æ•°æ®é›†ï¼ŒåŒ…æ‹¬äº†é™æ€ï¼ŒåŠ¨æ€ç­‰çº§çš„åœºæ™¯ï¼Œæ„Ÿè§‰é€‚åˆç”¨æ¥ä½œä¸ºéªŒè¯ã€‚
  - ä¸œäº¬å¤§å­¦ï¼Œ[code](https://github.com/kminoda/VIODE)

- W. Dai, Y. Zhang, P. Li, Z. Fang, and S. Scherer, â€œ**[RGB-D SLAM in Dynamic Environments Using Point Correlations](https://doi.org/10.1109/TPAMI.2020.3010942)**,â€ *IEEE Transactions on Pattern Analysis and Machine Intelligence*, pp. 1â€“1, 2020

  - æµ™å¤§ï¼Œä½¿ç”¨ç‚¹çš„å…³è”è¿›è¡ŒåŽ»é™¤ã€‚

- C. Huang, H. Lin, H. Lin, H. Liu, Z. Gao, and L. Huang, â€œYO-VIO: Robust Multi-Sensor Semantic Fusion Localization in Dynamic Indoor Environments,â€ in 2021 International Conference on Indoor Positioning and Indoor Navigation (IPIN), 2021.
  - ä½¿ç”¨yoloå’Œå…‰æµå¯¹è¿åŠ¨å¯¹è±¡è¿›è¡Œåˆ¤æ–­ï¼ŒåŽ»é™¤ç‰¹å¾ç‚¹åŽè¿›è¡Œå®šä½
  - VIOçš„ç»“åˆ

- Dynamic-VINSï¼šRGB-D Inertial Odometry for a Resource-restricted Robot in Dynamic Environments. 
  - åˆ†å‰²+è¿åŠ¨ç‚¹ç½®ä¿¡åº¦ï¼Œ[code](https://github.com/HITSZ-NRSL/Dynamic-VINS),[video](https://www.bilibili.com/video/BV1bF411t7mx)



# Dynamic Object Detection and ***Tracking***
- [Visual-Inertial Multi-Instance Dynamic SLAM with Object-level  Relocalisation (2022)](https://arxiv.org/pdf/2208.04274.pdf)
  - IROS 2022ï¼Œå®žéªŒå®¤ç½‘å€ï¼šhttps://mlr.in.tum.de/research/semanicobjectlevelanddynamicslam
- [Learning to Complete Object Shapes for Object-level Mapping in Dynamic  Scenes (2022)](https://arxiv.org/pdf/2208.05067.pdf)ï¼Œä¸Žä¸Šé¢æ˜¯åŒä¸€ä¸ªä½œè€…ï¼Œ
  - éƒ½æ˜¯åŸºäºŽMID-Fusionåšçš„ä¸œè¥¿ã€‚

- T. Ma and Y. Ou, â€œ[**MLO: Multi-Object Tracking and Lidar Odometry in Dynamic Environment**](http://arxiv.org/abs/2204.11621).â€ arXiv, Apr. 29, 2022
  - SLAM+MOTäº†
  
- Z. Wang, W. Li, Y. Shen, and B. Cai, â€œ**[4-D SLAM: An Efficient Dynamic Bayes Network-Based Approach for Dynamic Scene Understanding](https://doi.org/10.1109/ACCESS.2020.3042339)**,â€ *IEEE Access*
  - è¯­ä¹‰è¯†åˆ«åŠ¨æ€åŽï¼Œä½¿ç”¨UKFä¹‹ç±»çš„è¿›è¡ŒåŠ¨æ€è¿½è¸ªï¼Œä½†æ˜¯å›¾çš„æ•ˆæžœä¸å¥½ã€‚

- T. Ma and Y. Ou, â€œ**[MLO: Multi-Object Tracking and Lidar Odometry in Dynamic Environment](http://arxiv.org/abs/2204.11621)**.â€ , ArXiv 2022
  - åŸºäºŽLOAMçš„ç›®æ ‡è¿½è¸ªï¼Œåˆ†åˆ«å¯¹è¿åŠ¨å¯¹è±¡å’Œè‡ªèº«è¿›è¡Œä¼°è®¡ï¼Œä¹‹åŽè¿›è¡Œèžåˆã€‚å±žäºŽæ¾è€¦åˆçš„æ„Ÿè§‰

- R. Long, C. Rauch, T. Zhang, V. Ivan, T. L. Lam, and S. Vijayakumar, â€œ**[RGB-D SLAM in Indoor Planar Environments with Multiple Large Dynamic Objects](http://arxiv.org/abs/2203.02882)**,â€ 
  - å…ˆåšäº†åŠ¨æ€ç§»é™¤ï¼Œè¿™æ˜¯åŠ¨æ€è¿½è¸ªçš„ã€‚åœ¨ç»“æž„åŒ–çŽ¯å¢ƒï¼ˆé¢ï¼‰ä¸­è¿›è¡ŒSLAM+MOT

- â€œ**[AirDOS: Dynamic SLAM benefits from Articulated Objects,](http://arxiv.org/abs/2109.09903)**â€ Qiu Yuheng, et al. 2021(Arxiv)
  - [code](https://github.com/haleqiu/airdos)(TBA), [Paper](https://arxiv.org/abs/2109.09903), Video. **CMU RI**, Vision.
  
- â€œ[**DOT: Dynamic Object Tracking for Visual SLAM**](http://arxiv.org/abs/2010.00052).â€ Ballester, Irene, et al.(ICRA 2021)
  - code, [video](https://youtu.be/9hWChyQGKJk), **University of Zaragoza**, Vision
  
- Liu Yubao and Miura Jun. â€œ[**RDMO-SLAM: Real-Time Visual SLAM for Dynamic Environments Using Semantic Label Prediction With Optical Flow**](https://doi.org/10.1109/ACCESS.2021.3100426).â€ *IEEE Access*. 

- Kim Aleksandr, et al. â€œ[**EagerMOT: 3D Multi-Object Tracking via Sensor Fusion.**](http://arxiv.org/abs/2104.14682)â€ (*ICRA 2021*)
  - **TUM**, [code](https://github.com/aleksandrkim61/EagerMOT), [video](https://youtu.be/k8pKpvbenoM), Sensor Fusion.
  
- 1. Shan, Mo, et al. â€œ**[OrcVIO: Object Residual Constrained Visual-Inertial Odometry.](http://moshan.cf/orcvio_githubpage/0072.pdf)**â€ *(IROS2020)*
  2. Shan, Mo, et al. â€œ**[OrcVIO: Object Residual Constrained Visual-Inertial Odometry.](http://arxiv.org/abs/2007.15107)**â€ (IROS 2021)

  - [code](https://github.com/shanmo/OrcVIO), [video](http://moshan.cf/orcvio_githubpage/), [Project page](http://moshan.cf/orcvio_githubpage/).

- Rosen, David M., et al. â€œ[**Towards Lifelong Feature-Based Mapping in Semi-Static Environments.**](https://doi.org/10.1109/ICRA.2016.7487237)â€ *(ICRA 2016)*

- 1. Henein Mina, et al. â€œ[**Dynamic SLAM: The Need For Speed**](https://arxiv.org/abs/2002.08584v2).â€ *(ICRA 2020)*
  2. Zhang Jun, et al. â€œ**[VDO-SLAM: A Visual Dynamic Object-Aware SLAM System](http://arxiv.org/abs/2005.11052)**.â€ (ArXiv 2020)
  3. **[Robust Ego and Object 6-DoF Motion Estimation and Tracking](https://arxiv.org/abs/2007.13993v1)**,Jun Zhang, Mina Henein, Robert Mahony and Viorela Ila. IROS 2020([code](https://github.com/halajun/multimot_track))

  - [code](https://github.com/halajun/VDO_SLAM), [video](https://drive.google.com/file/d/1PbL4KiJ3sUhxyJSQPZmRP6mgi9dIC0iu/view), Vision
  
- Minoda, Koji, et al. â€œ**[VIODE: A Simulated Dataset to Address the Challenges of Visual-Inertial Odometry in Dynamic Environments.](https://arxiv.org/abs/2102.05965v1)**â€ (RAL 2021)

  - [**code_and dataset**](https://github.com/kminoda/VIODE), [video](https://youtu.be/LlFTyQf_dlo).

- Vincent, Jonathan, et al. â€œ[**Dynamic Object Tracking and Masking for Visual SLAM.**](https://arxiv.org/abs/2008.00072v1)â€, (IROS 2020)

  - [code](https://github.com/introlab/dotmask), video, 

- Huang, Jiahui, et al. â€œ**[ClusterVO: Clustering Moving Instances and Estimating Visual Odometry for Self and Surroundings](http://arxiv.org/abs/2003.12980)**.â€ (CVPR 2020)

  - Tsinghua, code, [video](https://youtu.be/paK-WCQpX-Y).[slides](https://cg.cs.tsinghua.edu.cn/people/~huangjh/clustervo-slides.pdf).

- Liu, Yuzhen, et al. â€œ**[A Switching-Coupled Backend for Simultaneous Localization and Dynamic Object Tracking.](https://github.com/zhuhu00/Awesome_Dynamic_SLAM/raw/main/pdfs/liu_2021_SwitchingCoupled.pdf)**â€ (RAL 2021)

  - Tsinghua

- Yang Charig, et al. â€œ**[Self-Supervised Video Object Segmentation by Motion Grouping](http://arxiv.org/abs/2104.07658)**.â€(ICCV 2021)

  - [Project page](https://charigyang.github.io/motiongroup/).

- Long Ran, et al. â€œ**[RigidFusion: Robot Localisation and Mapping in Environments with Large Dynamic Rigid Objects](http://arxiv.org/abs/2010.10841)**.â€ ,(RAL 2021)

  - [**project page**](https://conferences.inf.ed.ac.uk/rigidfusion/).code, video, 

- Yang Bohong, et al. â€œ**[Multi-Classes and Motion Properties for Concurrent Visual SLAM in Dynamic Environments.](https://doi.org/10.1109/TMM.2021.3110667)**â€ *IEEE Transactions on Multimedia*, 2021

- Yang Gengshan and Ramanan Deva. â€œ**[Learning to Segment Rigid Motions from Two Frames.](http://arxiv.org/abs/2101.03694)**â€ CVPR 2021

  - [Project page](https://www.contrib.andrew.cmu.edu/~gengshay/cvpr21rigidmask.html).

- Thomas Hugues, et al. â€œ**[Learning Spatiotemporal Occupancy Grid Maps for Lifelong Navigation in Dynamic Scenes.](http://arxiv.org/abs/2108.10585)**â€ 

  - [code](https://github.com/utiasASRL/Deep-Collison-Checker).

- Jung Dongki, et al. â€œ**[DnD: Dense Depth Estimation in Crowded Dynamic Indoor Scenes.](http://arxiv.org/abs/2108.05615)**â€ (ICCV 2021)

  - code, video.
  
- Luiten Jonathon, et al. â€œ[**Track to Reconstruct and Reconstruct to Track.**](https://arxiv.org/abs/1910.00130v3)â€, (RAL+ICRA 2020)

  - [code](https://github.com/tobiasfshr/MOTSFusion), [video](https://youtu.be/PMOYkpBwE78). **Reconstruct**.

- Grinvald, Margarita, et al. â€œ**[TSDF++: A Multi-Object Formulation for Dynamic Object Tracking and Reconstruction.](http://arxiv.org/abs/2105.07468)**â€(ICRA 2021)

  - [code](https://github.com/ethz-asl/tsdf-plusplus), [video](https://youtu.be/dSJmoeVasI0).

- **Wang Chieh-Chih, et al. â€œ[Simultaneous Localization, Mapping and Moving Object Tracking.](https://www.ri.cmu.edu/pub_files/pub4/wang_chieh_chih_2007_1/wang_chieh_chih_2007_1.pdf)â€ *The International Journal of Robotics Research 2007***

- Ran Teng, et al. â€œ**[RS-SLAM: A Robust Semantic SLAM in Dynamic Environments Based on RGB-D Sensor](https://doi.org/10.1109/JSEN.2021.3099511)**.â€ 

- Xu Hua, et al. â€œOD-SLAM: Real-Time Localization and Mapping in Dynamic Environment through Multi-Sensor Fusion.â€ * (ICARM 2020)* https://doi.org/10.1109/ICARM49381.2020.9195374.

- Wimbauer Felix, et al. â€œ**[MonoRec: Semi-Supervised Dense Reconstruction in Dynamic Environments from a Single Moving Camera.](http://arxiv.org/abs/2011.11814)**â€ (CVPR 2021)

  - **[Project page](https://vision.in.tum.de/research/monorec)**. [code](https://github.com/Brummi/MonoRec). [video](https://youtu.be/-gDSBIm0vgk). [video 2](https://youtu.be/-gDSBIm0vgk).

- Liu Yu, et al. â€œDynamic RGB-D SLAM Based on Static Probability and Observation Number.â€ *IEEE Transactions on Instrumentation and Measurement*, vol. 70, 2021, pp. 1â€“11. *IEEE Xplore*, https://doi.org/10.1109/TIM.2021.3089228.

- P. Li, T. Qin, and S. Shen, â€œ**[Stereo Vision-based Semantic 3D Object and Ego-motion Tracking for Autonomous Driving](http://arxiv.org/abs/1807.02062)**,â€ arXiv 2018

  - æ²ˆé‚µé¢‰è€å¸ˆç»„

- G. B. Nair *et al.*, â€œ**[Multi-object Monocular SLAM for Dynamic Environments](http://arxiv.org/abs/2002.03528)**,â€ IV2020

- M. RÃ¼nz and L. Agapito, â€œ[**Co-fusion: Real-time segmentation, tracking and fusion of multiple objects,**](https://doi.org/10.1109/ICRA.2017.7989518)â€ in *2017 IEEE International Conference on Robotics and Automation (ICRA)*, May 2017, pp. 4471â€“4478.

  - [code](https://github.com/martinruenz/co-fusion), 

- [TwistSLAM: Constrained SLAM in Dynamic Environment](https://arxiv.org/pdf/2202.12384),
  - S3LAMçš„åŽç»­ï¼Œä½¿ç”¨å…¨æ™¯åˆ†å‰²ä½œä¸ºæ£€æµ‹çš„å‰ç«¯

# Object SLAM & Application

- **CubeSLAM: Monocular 3D Object SLAM**, IEEE Transactions on Robotics 2019, S. Yang, S. Scherer [**PDF**](https://arxiv.org/abs/1806.00557)
  - [code](https://github.com/shichaoy/cube_slam). [video](https://youtu.be/QnVlexXi9_c). Vision
- Salas-Moreno Renato F., et al. â€œ**[SLAM++: Simultaneous Localisation and Mapping at the Level of Objects.](https://doi.org/10/ggmwnd)**â€ (CVPR 2013)
  - code, [video](https://youtu.be/tmrAh1CqCRo),
- Nicholson Lachlan, et al. â€œ**[QuadricSLAM: Dual Quadrics From Object Detections as Landmarks in Object-Oriented SLAM](https://arxiv.org/abs/1804.04011)**.â€ (RAL-2018)
  - [**Project page**](https://nikosuenderhauf.github.io/semanticslam.ai/quadricslam.html), [code](https://github.com/tiev-tongji/quadric_slam-deprecated).
- Wu Yanmin, et al. â€œ[**EAO-SLAM: Monocular Semi-Dense Object SLAM Based on Ensemble Data Association**](https://arxiv.org/abs/2004.12730).â€ *2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)*, Oct. 2020, pp. 4966â€“73. *arXiv.org*, https://doi.org/10.1109/IROS45743.2020.9341757.
  - [Project page](https://yanmin-wu.github.io/project/eaoslam/). [code](https://github.com/yanmin-wu/EAO-SLAM).  
- H. Osman, N. Darwish, and A. Bayoumi, â€œLoopNet: Where to Focus Detecting Loop Closures in Dynamic Scenes,â€ *IEEE Robotics and Automation Letters*, pp. 1â€“1, 2022, doi: [10.1109/LRA.2022.3142901](https://doi.org/10.1109/LRA.2022.3142901).
  - åŠ¨æ€çŽ¯å¢ƒä¸­çš„å›žçŽ¯æ£€æµ‹ï¼Œç½‘ç»œã€‚codeï¼Œvideo

- M. N. Finean, L. PetroviÄ‡, W. Merkt, I. MarkoviÄ‡, and I. Havoutis, â€œ**[Motion Planning in Dynamic Environments Using Context-Aware Human Trajectory Prediction](http://arxiv.org/abs/2201.05058)**,â€ *arXiv:2201.05058 [cs]*, Jan. 2022.
  - å«æœ‰äººçš„åŠ¨æ€çŽ¯å¢ƒçš„å¯¼èˆªï¼Œ**[code](https://github.com/ori-drs/integrated-dynamic-motion-planning-framework)**ï¼Œ**[video](https://www.youtube.com/watch?v=gdC3mpZNjG4&t=5s)**ã€‚ç±»ä¼¼é¿éšœå’Œè§„åˆ’ç±»çš„


# Researchers

## ðŸ¥¼1. Berta Bescos

> **ä¸»é¡µï¼š[è°·æ­Œå­¦æœ¯](https://scholar.google.hk/citations?user=8koVpHwAAAAJ&hl=it) | [ä¸ªäººä¸»é¡µ](https://bertabescos.github.io/) | [GitHub](https://github.com/BertaBescos)**

> **åšå£«å­¦ä½è®ºæ–‡ï¼š [Visual slam in dynamic environments](https://zaguan.unizar.es/record/100672)**

> **ä»£è¡¨æ€§å·¥ä½œ**

- **[1]** Bescos B, FÃ¡cil J M, Civera J, et al. [DynaSLAM: Tracking, mapping, and inpainting in dynamic scenes](https://arxiv.org/pdf/1806.05620.pdf)[J]. IEEE Robotics and Automation Letters, **2018**, 3(4): 4076-4083.
- **[2]** Bescos B, Neira J, Siegwart R, et al. [Empty cities: Image inpainting for a dynamic-object-invariant space](https://arxiv.org/pdf/1809.10239.pdf)[C]//2019 International Conference on Robotics and Automation (ICRA). IEEE, **2019**: 5460-5466.
- **[3]** Bescos B, Cadena C, Neira J. [Empty cities: A dynamic-object-invariant space for visual SLAM](https://arxiv.org/pdf/2010.07646.pdf)[J]. IEEE Transactions on Robotics, **2020**, 37(2): 433-451.
- **[4]** Bescos B, Campos C, TardÃ³s J D, et al. [DynaSLAM II: Tightly-coupled multi-object tracking and SLAM](https://arxiv.org/pdf/2010.07820.pdf)[J]. IEEE Robotics and Automation Letters, **2021**, 6(3): 5191-5198.

## ðŸ¥¼2. Yubao Liu

[Walk Into AI World](https://www.ybliu.com/)

> ä¸»é¡µï¼š[è°·æ­Œå­¦æœ¯](https://scholar.google.com/citations?user=P4M6ru0AAAAJ&hl=zh-CN) | [GitHub](https://github.com/yubaoliu)

> ä»£è¡¨æ€§å·¥ä½œï¼š

1. RDS-SLAM: real-time dynamic SLAM using semantic segmentation methods
2. KMOP-vSLAM: Dynamic Visual SLAM for RGB-D Cameras using K-means and OpenPose
3. RDMO-SLAM: Real-time Visual SLAM for Dynamic Environments using Semantic Label Prediction with Optical Flow
#### 3. Guoquan Huang(SLAMMOT)


#### 4. Shenshao Jie(MOT)
